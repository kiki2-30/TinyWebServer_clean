# 10500并发测试 - 完整检查清单

## ✅ 代码层面检查结果

| 检查项 | 当前配置 | 推荐值 | 状态 | 说明 |
|--------|----------|--------|------|------|
| **MAX_FD** | 65,536 | ≥10,500 | ✅ 通过 | 支持最多65536个连接 |
| **MAX_EVENT_NUMBER** | 20,000 | ≥10,500 | ✅ 通过 | epoll事件数组足够 |
| **users数组** | 65,536 | ≥10,500 | ✅ 通过 | http_conn对象数组足够 |
| **线程池请求队列** | 20,000 | ≥10,500 | ✅ **已修改** | 从10000改为20000 |
| **listen队列** | 1,024 | ≥512 | ✅ 通过 | 半连接队列backlog |
| **读缓冲区** | 2,048 字节 | - | ✅ 合理 | 每连接2KB |
| **写缓冲区** | 1,024 字节 | - | ✅ 合理 | 每连接1KB |

---

## ✅ 系统层面检查结果

| 检查项 | 当前值 | 推荐值 | 状态 | 如何修改 |
|--------|--------|--------|------|----------|
| **文件描述符限制** | 1,048,576 | ≥65,536 | ✅ 充足 | `ulimit -n 65536` |
| **somaxconn** | 16,384 | ≥16,384 | ✅ 充足 | `sudo sysctl -w net.core.somaxconn=16384` |
| **tcp_max_syn_backlog** | 16,384 | ≥16,384 | ✅ 充足 | `sudo sysctl -w net.ipv4.tcp_max_syn_backlog=16384` |
| **端口范围** | 1024-65535 | ≥10,500 | ✅ 充足 | `sudo sysctl -w net.ipv4.ip_local_port_range="1024 65535"` |

---

## 📝 测试前准备

### 1. 确保系统参数已优化

```bash
# 检查当前参数
cat /proc/sys/net/core/somaxconn
cat /proc/sys/net/ipv4/tcp_max_syn_backlog
cat /proc/sys/net/ipv4/ip_local_port_range
ulimit -n

# 如果参数不足，执行优化
sudo sysctl -w net.core.somaxconn=16384
sudo sysctl -w net.ipv4.tcp_max_syn_backlog=16384
sudo sysctl -w net.ipv4.ip_local_port_range="1024 65535"
ulimit -n 65536
```

### 2. 重新编译服务器

```bash
cd /home/kiki/TinyWebServer_clean
make clean
make
```

### 3. 检查WebBench是否可用

```bash
cd test_pressure/webbench-1.5
ls -la webbench  # 检查可执行文件
./webbench -? # 查看帮助
```

---

## 🚀 测试执行

### 方式1: 使用自动化脚本（推荐）

```bash
cd /home/kiki/TinyWebServer_clean
./压测10500.sh
```

### 方式2: 手动执行

```bash
# 1. 启动服务器
./server -c 1 -m 1 -a 0 -s 8 -t 64 &

# 2. 等待3秒
sleep 3

# 3. 执行压测
cd test_pressure/webbench-1.5
./webbench -c 10500 -t 5 http://127.0.0.1:9006/judge.html
```

---

## 📊 不同配置的性能对比建议

### 测试矩阵

| 测试组 | 模式 | 线程数 | 并发数 | 预期QPS | 用途 |
|--------|------|--------|--------|---------|------|
| 1 | Proactor LT+LT `-m 0` | 32 | 3000 | 10K+ | 基础测试 |
| 2 | Proactor LT+ET `-m 1` | 32 | 3000 | 12K+ | 性能对比 |
| 3 | Proactor ET+ET `-m 3` | 32 | 3000 | 11K+ | 性能对比 |
| 4 | Proactor LT+ET `-m 1` | 64 | 5000 | 15K+ | 扩展性测试 |
| 5 | Proactor LT+ET `-m 1` | 64 | 10500 | 20K+ | 极限测试 |

### 测试命令

```bash
# 测试1: 基础配置（LT+LT）
./server -c 1 -m 0 -a 0 -s 8 -t 32 &
./webbench -c 3000 -t 30 http://127.0.0.1:9006/judge.html
pkill server

# 测试2: 优化配置（LT+ET）
./server -c 1 -m 1 -a 0 -s 8 -t 32 &
./webbench -c 3000 -t 30 http://127.0.0.1:9006/judge.html
pkill server

# 测试3: 高线程（LT+ET, 64线程）
./server -c 1 -m 1 -a 0 -s 8 -t 64 &
./webbench -c 5000 -t 30 http://127.0.0.1:9006/judge.html
pkill server

# 测试4: 极限测试（10500并发）
./server -c 1 -m 1 -a 0 -s 8 -t 64 &
./webbench -c 10500 -t 5 http://127.0.0.1:9006/judge.html
pkill server
```

---

## ⚠️ 潜在问题和解决方案

### 问题1: WebBench报错 "fork failed"

**原因**: 10500个子进程超过系统限制

**解决方案**:
```bash
# 增加进程限制
ulimit -u 20000
```

### 问题2: 连接被拒绝

**原因**: 
- 半连接队列满
- 全连接队列满
- listen backlog太小

**解决方案**: 
- 已在代码中设置 `listen(fd, 1024)`
- 系统参数已优化为16384

### 问题3: 端口耗尽

**原因**: 客户端端口用完（TIME_WAIT状态占用）

**解决方案**:
```bash
# 启用TIME_WAIT重用
sudo sysctl -w net.ipv4.tcp_tw_reuse=1

# 缩短TIME_WAIT超时时间
sudo sysctl -w net.ipv4.tcp_fin_timeout=30
```

### 问题4: 服务器崩溃

**原因**: 
- 内存不足（OOM）
- 段错误（数组越界）

**解决方案**:
- 监控内存使用: `free -m`
- 查看崩溃日志: `dmesg | tail`
- 使用gdb调试: `ulimit -c unlimited`

### 问题5: 性能不如预期

**原因**: WSL2虚拟化损耗

**解决方案**:
- 接受虚拟化环境的性能损耗（20-40%）
- 在物理机或云服务器上重新测试
- 关注稳定性而不是绝对数值

---

## 📈 性能监控

### 实时监控命令

```bash
# 终端1: 运行服务器
./server -c 1 -m 1 -a 0 -s 8 -t 64

# 终端2: 监控CPU和内存
top -p $(pgrep server)

# 终端3: 监控网络连接
watch -n 1 'ss -s | grep TCP'

# 终端4: 执行压测
./webbench -c 10500 -t 30 http://127.0.0.1:9006/judge.html
```

### 记录性能指标

测试完成后记录：
- ✅ QPS（每秒请求数）
- ✅ 成功率（成功/总请求）
- ✅ CPU使用率
- ✅ 内存使用量
- ✅ 平均响应时间
- ✅ 错误日志（如果有）

---

## 🎯 总结

### 代码已准备就绪 ✅

您的代码**已经可以支持10500并发测试**：

1. ✅ MAX_FD = 65536（足够）
2. ✅ MAX_EVENT_NUMBER = 20000（足够）
3. ✅ 线程池请求队列 = 20000（已优化）
4. ✅ listen队列 = 1024（已优化）
5. ✅ 系统参数已配置正确

### WSL2环境说明

在WSL2环境下，预期性能会比物理机低20-40%，这是**正常现象**。

- 原作者在物理机: 93251 QPS
- 您在WSL2预期: 50000-70000 QPS (10500并发)
- 您在WSL2实际: 10000-20000 QPS (3000并发)

### 建议

1. **先测试3000并发**，确保稳定
2. **逐步增加**到5000、8000、10500
3. **记录每个阶段**的QPS、成功率、资源使用
4. **面试时展示完整的测试过程**，比单一数字更有说服力

---

## 📞 快速命令参考

```bash
# 一键测试
./压测10500.sh

# 查看服务器状态
ps aux | grep server

# 停止服务器
pkill server

# 清理TIME_WAIT连接
sudo sysctl -w net.ipv4.tcp_tw_recycle=1
```

